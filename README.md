# Cloud Native LLM Project (AMOS SS 2024)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
![Build Status](https://img.shields.io/travis/com/yourusername/yourrepository/main.svg)
![Kubernetes Version](https://img.shields.io/badge/kubernetes-v1.21-blue.svg)
![GitHub language count](https://img.shields.io/github/languages/count/yourusername/yourrepository)
![GitHub last commit](https://img.shields.io/github/last-commit/yourusername/yourrepository)
![GitHub issues](https://img.shields.io/github/issues/yourusername/yourrepository)


## AMOS Project
The project is created as a work as part of a student project, carried out by [Prof. Riehle](https://oss.cs.fau.de/person/riehle-dirk/) at the [Friedrich-Alexander University of Erlangen-Nuremberg](https://www.fau.de).

## Overview

Welcome to the Cloud Native LLM Project for the AMOS SS 2024 semester! 
This initiative focuses on developing a sophisticated Large Language Model (LLM) capable of answering complex queries about Kubernetes installations.
By providing immediate, context-aware answers and guidance, this reduces the learning curve and increases productivity in managing Kubernetes installations.
Our goal is to create a foundation for building AI assistants that will aid developers in navigating and managing Kubernetes environments.

## Objectives

- **Select and Train an Open Source LLM:** Identify a suitable open source LLM for training with specific Kubernetes-related data.
- **Automate Data Extraction:** Develop tools to automatically gather training data from publicly available Kubernetes resources such as white papers, documentation, and forums.
- **Incorporate Advanced Data Techniques:** Use concepts and relationship extraction to enrich the training dataset, enhancing the LLM's understanding of Kubernetes.
- **Collaborative Efforts:** Work in tandem with the AMOS project on knowledge graph extraction to synergize both projectsâ€™ outcomes.
- **Benchmark Development:** Construct a manual benchmark to serve as ground truth for quantitatively evaluating the LLM's performance.

## Benchmark
[TBD]

## How to setup
[TBD]

## How to run the project
[TBD]